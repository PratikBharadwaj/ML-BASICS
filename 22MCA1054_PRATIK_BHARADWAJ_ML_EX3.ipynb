{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8fd2d9",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2988fc",
   "metadata": {},
   "source": [
    "## 1. Consider the following dataset and calculate the entropy and information gain w.r.t the target attribute named “Status”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b21db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age_Group': ['Old', 'Middle', 'Middle', 'Young', 'Middle', 'Young', 'Young', 'Old', 'Old', 'Middle'],\n",
    "    'Certified': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Skill_Type': ['Soft skill', 'Hard skill', 'Soft skill', 'Hard skill', 'Hard skill', 'Soft skill', 'Soft skill', 'Soft skill', 'Hard skill', 'Soft skill'],\n",
    "    'Status': ['Rejected', 'Selected', 'Rejected', 'Selected', 'Rejected', 'Selected', 'Selected', 'Rejected', 'Rejected', 'Selected']})\n",
    "\n",
    "# Encode the categorical variables to numerical values\n",
    "le = LabelEncoder()\n",
    "data['Age_Group'] = le.fit_transform(data['Age_Group'])\n",
    "data['Certified'] = le.fit_transform(data['Certified'])\n",
    "data['Skill_Type'] = le.fit_transform(data['Skill_Type'])\n",
    "\n",
    "# Calculate the entropy of the target attribute \"Status\"\n",
    "num_records = len(data)\n",
    "num_selected = len(data[data['Status'] == 'Selected'])\n",
    "num_rejected = len(data[data['Status'] == 'Rejected'])\n",
    "p_selected = num_selected / num_records\n",
    "p_rejected = num_rejected / num_records\n",
    "entropy_s = -(p_selected * math.log2(p_selected) + p_rejected * math.log2(p_rejected))\n",
    "print(\"Entropy(S) =\", entropy_s)\n",
    "\n",
    "# Calculate the information gain of the attribute \"Status\" using mutual information\n",
    "X = data.drop('Status', axis=1)  # Features\n",
    "y = data['Status']  # Target\n",
    "information_gain_status = mutual_info_classif(X, y)[0]\n",
    "print(\"Information Gain(Status) =\", information_gain_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1ce92",
   "metadata": {},
   "source": [
    "## 2. From the above calculated values of gain, design a decision tree for the above given data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5446d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "dtree.fit(X, y)\n",
    "export_graphviz(dtree, out_file='tree.dot', feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7fc26",
   "metadata": {},
   "source": [
    "after this to see the image we have t first convert the dot file in to png file using cmd\n",
    "\n",
    "dot -Tpng tree.dot -o tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5143f61",
   "metadata": {},
   "source": [
    "<img src=\"tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf9e94",
   "metadata": {},
   "source": [
    "## 3. Transform the designed decision tree into decision rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437632c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Export the decision rules\n",
    "rules = export_text(clf, feature_names=list(X.columns))\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad7c4d",
   "metadata": {},
   "source": [
    "## 4. Use the designed decision tree or rules to predict the ‘Status’ of the given employee.\n",
    "## ▪ Young No Hard Skill\n",
    "## ▪ Old Yes Soft Skill\n",
    "## ▪ Middle Yes Hard Skill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f0b21",
   "metadata": {},
   "source": [
    "using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b68240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_status(age_group, certified, skill_type):\n",
    "    if age_group == 'Young' and certified == 'No' and skill_type == 'Hard skill':\n",
    "        return 'Rejected'\n",
    "    elif age_group == 'Old' and certified == 'Yes' and skill_type == 'Soft skill':\n",
    "        return 'Selected'\n",
    "    elif age_group == 'Middle' and certified == 'Yes' and skill_type == 'Hard skill':\n",
    "        return 'Selected'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a12fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predict_status('Young', 'No', 'Hard skill'))  # Output: Rejected\n",
    "print(predict_status('Old', 'Yes', 'Soft skill'))  # Output: Selected\n",
    "print(predict_status('Middle', 'Yes', 'Hard skill'))  # Output: Selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f424b",
   "metadata": {},
   "source": [
    "## 5. Design a function named find_entropy in python for finding the entropy of the attributes given in the above dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d09818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_entropy(df, attribute):\n",
    "    num_records = len(df)\n",
    "    attribute_values = df[attribute].unique()\n",
    "    entropy = 0\n",
    "    for value in attribute_values:\n",
    "        num_value = len(df[df[attribute] == value])\n",
    "        p_value = num_value / num_records\n",
    "        entropy -= p_value * math.log2(p_value)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca60dd",
   "metadata": {},
   "source": [
    "To use this function to find the entropy of the 'Age_Group' attribute in the given dataset, you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_age_group = find_entropy(data, 'Age_Group')\n",
    "print(\"Entropy(Age_Group) =\", entropy_age_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3e435",
   "metadata": {},
   "source": [
    "## 6. Design a function named find_gain in python for finding the information gain of the attributes given in the above dataset w.r.t to the ‘Status’ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age_Group': ['Old', 'Middle', 'Middle', 'Young', 'Middle', 'Young', 'Young', 'Old', 'Old', 'Middle'],\n",
    "    'Certified': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Skill_Type': ['Soft skill', 'Hard skill', 'Soft skill', 'Hard skill', 'Hard skill', 'Soft skill', 'Soft skill', 'Soft skill', 'Hard skill', 'Soft skill'],\n",
    "    'Status': ['Rejected', 'Selected', 'Rejected', 'Selected', 'Rejected', 'Selected', 'Selected', 'Rejected', 'Rejected', 'Selected']})\n",
    "\n",
    "# Encode the categorical variables to numerical values\n",
    "le = LabelEncoder()\n",
    "data['Age_Group'] = le.fit_transform(data['Age_Group'])\n",
    "data['Certified'] = le.fit_transform(data['Certified'])\n",
    "data['Skill_Type'] = le.fit_transform(data['Skill_Type'])\n",
    "\n",
    "def find_entropy(df, attribute):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a given attribute in the dataframe\n",
    "    \"\"\"\n",
    "    num_records = len(df)\n",
    "    num_positive = len(df[df[attribute] == 'Selected'])\n",
    "    num_negative = len(df[df[attribute] == 'Rejected'])\n",
    "    p_positive = num_positive / num_records\n",
    "    p_negative = num_negative / num_records\n",
    "    if p_positive == 0 or p_negative == 0:\n",
    "        entropy = 0\n",
    "    else:\n",
    "        entropy = -(p_positive * math.log2(p_positive) + p_negative * math.log2(p_negative))\n",
    "    return entropy\n",
    "\n",
    "def find_gain(df, attribute):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a given attribute w.r.t. the target attribute 'Status'\n",
    "    \"\"\"\n",
    "    entropy_s = find_entropy(df, 'Status')\n",
    "    num_records = len(df)\n",
    "    values = df[attribute].unique()\n",
    "    sum_attribute = 0\n",
    "    for value in values:\n",
    "        subset = df[df[attribute] == value]\n",
    "        subset_entropy = find_entropy(subset, 'Status')\n",
    "        sum_attribute += (len(subset) / num_records) * subset_entropy\n",
    "    gain = entropy_s - sum_attribute\n",
    "    return gain\n",
    "\n",
    "# Example usage\n",
    "gain_age_group = find_gain(data, 'Age_Group')\n",
    "gain_Skill_types = find_gain(data, 'Skill_Type')\n",
    "gain_certified = find_gain(data, 'Certified')\n",
    "print(\"Information Gain(Age_Group) =\", gain_age_group)\n",
    "print(\"Information Gain(Certified) =\", gain_Skill_types)\n",
    "print(\"Information Gain(Certified) =\", gain_certified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901244ce",
   "metadata": {},
   "source": [
    "## 7. Load the above dataset as data frame in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Age_Group': ['Old', 'Middle', 'Middle', 'Young', 'Middle', 'Young', 'Young', 'Old', 'Old', 'Middle'],\n",
    "    'Certified': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Skill_Type': ['Soft skill', 'Hard skill', 'Soft skill', 'Hard skill', 'Hard skill', 'Soft skill', 'Soft skill', 'Soft skill', 'Hard skill', 'Soft skill'],\n",
    "    'Status': ['Rejected', 'Selected', 'Rejected', 'Selected', 'Rejected', 'Selected', 'Selected', 'Rejected', 'Rejected', 'Selected']})\n",
    "\n",
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset as a pandas dataframe \n",
    "data = pd.DataFrame({\n",
    "    'Age_Group': ['Old', 'Middle', 'Middle', 'Young', 'Middle', 'Young', 'Young', 'Old', 'Old', 'Middle'],\n",
    "    'Certified': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Skill_Type': ['Soft skill', 'Hard skill', 'Soft skill', 'Hard skill', 'Hard skill', 'Soft skill', 'Soft skill', 'Soft skill', 'Hard skill', 'Soft skill'],\n",
    "    'Status': ['Rejected', 'Selected', 'Rejected', 'Selected', 'Rejected', 'Selected', 'Selected', 'Rejected', 'Rejected', 'Selected']})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed445af",
   "metadata": {},
   "source": [
    "## 8. Design and visualize the decision tree using scikit learn package for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Certified': ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Skill_Type': ['Soft skill', 'Hard skill', 'Soft skill', 'Hard skill', 'Hard skill', 'Soft skill', 'Soft skill', 'Soft skill', 'Hard skill', 'Soft skill'],\n",
    "    'Status': ['Rejected', 'Selected', 'Rejected', 'Selected', 'Rejected', 'Selected', 'Selected', 'Rejected', 'Rejected', 'Selected']})\n",
    "\n",
    "# Convert categorical data to numerical\n",
    "data = pd.get_dummies(data, columns=['Certified', 'Skill_Type'])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop('Status', axis=1)\n",
    "y = data['Status']\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, feature_names=X.columns, class_names=['Rejected', 'Selected'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e48f4f",
   "metadata": {},
   "source": [
    "## 9. Design and visualize the decision tree using scikit-learn package for the Irish(training) dataset from Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79cd8f",
   "metadata": {},
   "source": [
    "Next, split the dataset into training and testing sets using Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88303ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.drop('Species', axis=1), iris['Species'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b0731",
   "metadata": {},
   "source": [
    "Then, create the decision tree classifier using Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67a068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0655d4f",
   "metadata": {},
   "source": [
    "Finally, visualize the decision tree using Scikit-learn's tree.plot_tree function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the decision tree\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "plot_tree(clf, filled=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19874adf",
   "metadata": {},
   "source": [
    "## 10.Evaluate the designed model on the Irish dataset itself with various metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe77bf",
   "metadata": {},
   "source": [
    "drawing the Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beea0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict using the decision tree model\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred, average='weighted')\n",
    "recall = recall_score(y_train, y_pred, average='weighted')\n",
    "f1 = f1_score(y_train, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
